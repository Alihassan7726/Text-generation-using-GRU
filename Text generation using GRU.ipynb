{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "pd.set_option('max_colwidth', 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ali\\NLP , Naive Baise , SVM\\RNN , LSTM , NER modeling , Language models\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd() # string representation of current directory.\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\BEPEC Python Material\\DataSets , NLP datasets\n"
     ]
    }
   ],
   "source": [
    "%cd \"C:/BEPEC Python Material/DataSets , NLP datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 8E49-65D4\n",
      "\n",
      " Directory of C:\\BEPEC Python Material\\DataSets , NLP datasets\n",
      "\n",
      "05/04/2021  02:27 PM    <DIR>          .\n",
      "05/04/2021  02:27 PM    <DIR>          ..\n",
      "05/04/2021  02:27 PM        62,726,972 abcnews-date-text.csv\n",
      "10/09/2020  11:03 AM            10,288 data from third party source.docx\n",
      "10/09/2020  11:03 AM            10,203 data.docx\n",
      "04/30/2021  10:04 AM        25,144,581 fake_news_test.csv\n",
      "04/30/2021  10:03 AM        98,628,550 fake_news_train.csv\n",
      "10/09/2020  11:03 AM           410,624 INX Fututre.xls\n",
      "05/03/2021  10:33 AM           657,824 socrates.txt\n",
      "               7 File(s)    187,589,042 bytes\n",
      "               2 Dir(s)  43,155,476,480 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\BEPEC Python Material\\DataSets , NLP datasets\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd() # string representation of current directory.\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20030219</td>\n",
       "      <td>aba decides against community broadcasting licence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20030219</td>\n",
       "      <td>act fire witnesses must be aware of defamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20030219</td>\n",
       "      <td>a g calls for infrastructure protection summit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20030219</td>\n",
       "      <td>air nz staff in aust strike for pay rise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20030219</td>\n",
       "      <td>air nz strike to affect australian travellers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   publish_date                                       headline_text\n",
       "0      20030219  aba decides against community broadcasting licence\n",
       "1      20030219      act fire witnesses must be aware of defamation\n",
       "2      20030219      a g calls for infrastructure protection summit\n",
       "3      20030219            air nz staff in aust strike for pay rise\n",
       "4      20030219       air nz strike to affect australian travellers"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for filename in os.listdir(path):\n",
    "    if \"abcnews\" in filename:\n",
    "        df = pd.read_csv(path+'/'+filename)\n",
    "df.head()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1226258 entries, 0 to 1226257\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count    Dtype \n",
      "---  ------         --------------    ----- \n",
      " 0   publish_date   1226258 non-null  int64 \n",
      " 1   headline_text  1226258 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 18.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>978636</th>\n",
       "      <td>20150914</td>\n",
       "      <td>gst changes could raise $30 billion even after low income compensation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997900</th>\n",
       "      <td>20151206</td>\n",
       "      <td>increasing gst to 15 pc could raise $27 billion grattan institute says</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748563</th>\n",
       "      <td>20121213</td>\n",
       "      <td>salvation army determined to deliver on nauru despite tough conditions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876069</th>\n",
       "      <td>20140522</td>\n",
       "      <td>bland shire council revokes plans to build $5.4 million sports complex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998246</th>\n",
       "      <td>20151208</td>\n",
       "      <td>berri barmera council gets $3.5 million for multipurpose sports centre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        publish_date  \\\n",
       "978636      20150914   \n",
       "997900      20151206   \n",
       "748563      20121213   \n",
       "876069      20140522   \n",
       "998246      20151208   \n",
       "\n",
       "                                                                 headline_text  \n",
       "978636  gst changes could raise $30 billion even after low income compensation  \n",
       "997900  increasing gst to 15 pc could raise $27 billion grattan institute says  \n",
       "748563  salvation army determined to deliver on nauru despite tough conditions  \n",
       "876069  bland shire council revokes plans to build $5.4 million sports complex  \n",
       "998246  berri barmera council gets $3.5 million for multipurpose sports centre  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## We will be taking 50000 long headlines\n",
    "df = df.iloc[df['headline_text'].apply(lambda x : len(x)).sort_values(ascending = False).index].head(50000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gst changes could raise $30 billion even after low income compensation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>increasing gst to 15 pc could raise $27 billion grattan institute says</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>salvation army determined to deliver on nauru despite tough conditions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bland shire council revokes plans to build $5.4 million sports complex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>berri barmera council gets $3.5 million for multipurpose sports centre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            headline_text\n",
       "0  gst changes could raise $30 billion even after low income compensation\n",
       "1  increasing gst to 15 pc could raise $27 billion grattan institute says\n",
       "2  salvation army determined to deliver on nauru despite tough conditions\n",
       "3  bland shire council revokes plans to build $5.4 million sports complex\n",
       "4  berri barmera council gets $3.5 million for multipurpose sports centre"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.reset_index()\n",
    "print(len(df))\n",
    "df.drop(columns = ['index' , 'publish_date'] , inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['gst changes could raise $30 billion even after low income compensation',\n",
       " 'increasing gst to 15 pc could raise $27 billion grattan institute says',\n",
       " 'salvation army determined to deliver on nauru despite tough conditions',\n",
       " 'bland shire council revokes plans to build $5.4 million sports complex',\n",
       " 'berri barmera council gets $3.5 million for multipurpose sports centre']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines = []\n",
    "headlines.extend(list(df[\"headline_text\"].values))\n",
    "print(len(headlines))\n",
    "headlines[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gst changes could raise 30 billion even after low income compensation',\n",
       " 'increasing gst to 15 pc could raise 27 billion grattan institute says',\n",
       " 'salvation army determined to deliver on nauru despite tough conditions',\n",
       " 'bland shire council revokes plans to build 54 million sports complex',\n",
       " 'berri barmera council gets 35 million for multipurpose sports centre']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "def clean_text(headline):\n",
    "    text = \"\".join( word for word in headline if word not in string.punctuation ).lower()\n",
    "    text = text.encode(\"utf8\").decode(\"ascii\", \"ignore\")\n",
    "    return text\n",
    "\n",
    "corpus = [ clean_text(headline) for headline in headlines ]\n",
    "corpus[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['us broadcaster abc news reporters story about epstein was kill',\n",
       " 'scotland march for independence attracts thousands post brexit',\n",
       " 'artist ben quilty painting dark australian history myall creek',\n",
       " 'cannabis plants budding success in secret tasmanian greenhouse',\n",
       " 'fishermen stranded boat ute trailer swept away buffalo creek']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[len(corpus)-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating sequence of N-gram tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35005\n"
     ]
    }
   ],
   "source": [
    "vocab = []\n",
    "for line in corpus:\n",
    "    words = line.split()\n",
    "    for word in words:\n",
    "        vocab.append(word)\n",
    "\n",
    "vocablary = set(vocab)\n",
    "print(len(vocablary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35005"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "word2index = tokenizer.word_index\n",
    "len(word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2index.get('and')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {}\n",
    "rev_dictionary = {}\n",
    "for word, idx in word2index.items():\n",
    "    dictionary[word] = idx\n",
    "    rev_dictionary[idx] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump\n",
    "# saving the tokenizer\n",
    "dump(tokenizer, open('tokenizer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35005"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(rev_dictionary.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "input_seqences = tokenizer.texts_to_sequences(corpus)\n",
    "print(len(input_seqences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1484, 186, 45, 784, 1180, 420, 4164, 7, 711, 2171, 651],\n",
       " [2398, 1484, 1, 1114, 7879, 45, 784, 3664, 420, 2225, 2226, 13],\n",
       " [2572, 737, 4165, 1, 2070, 5, 1098, 213, 1282, 729],\n",
       " [14269, 1485, 60, 10008, 268, 1, 1131, 14270, 136, 1302, 3665],\n",
       " [11641, 19139, 60, 384, 3134, 136, 4, 19140, 1302, 157]]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seqences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1484],\n",
       " [1484, 186],\n",
       " [1484, 186, 45],\n",
       " [1484, 186, 45, 784],\n",
       " [1484, 186, 45, 784, 1180],\n",
       " [1484, 186, 45, 784, 1180, 420],\n",
       " [1484, 186, 45, 784, 1180, 420, 4164],\n",
       " [1484, 186, 45, 784, 1180, 420, 4164, 7],\n",
       " [1484, 186, 45, 784, 1180, 420, 4164, 7, 711],\n",
       " [2398]]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = []\n",
    "target = []\n",
    "for line in input_seqences:\n",
    "    for i in range(1, len(line)-1):\n",
    "        input_data.append(line[:i])\n",
    "        target.append(line[i+1])\n",
    "input_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[45, 784, 1180, 420, 4164, 7, 711]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LEN = 0\n",
    "for seq in input_data:\n",
    "    if len(seq) > MAX_LEN:\n",
    "        MAX_LEN = len(seq)\n",
    "MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(382713, 13)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = pad_sequences(input_data, maxlen=MAX_LEN, padding=\"post\", truncating=\"post\")\n",
    "print(len(input_data[0]))\n",
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 49.9 GiB for an array with shape (382713, 35006) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-371ac8b1f9f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mvocab_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword2index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvocab_size\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensor_ali\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[1;34m(y, num_classes, dtype)\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mnum_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m   \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m   \u001b[0mcategorical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m   \u001b[0mcategorical\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m   \u001b[0moutput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 49.9 GiB for an array with shape (382713, 35006) and data type float32"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word2index)+1\n",
    "target = to_categorical(target, num_classes=vocab_size )\n",
    "print(target.shape)\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
